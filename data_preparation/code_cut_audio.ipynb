{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import whisperx\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "\n",
    "MODEL_SIZE = \"large\" \n",
    "DEVICE = \"cpu\" #cuda\n",
    "COMPUTE_TYPE = \"float32\"\n",
    "\n",
    "print(f\"Loading Whisper model: {MODEL_SIZE}...\")\n",
    "model = whisperx.load_model(MODEL_SIZE, device=DEVICE, compute_type=COMPUTE_TYPE)\n",
    "model_a, metadata = whisperx.load_align_model(language_code=\"vi\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_audio(input_dir, output_dir, other_dir, target_duration, stride):\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if not filename.lower().endswith((\".wav\", \".mp3\")):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        print(f\"\\nProcessing: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            result = model.transcribe(input_path)\n",
    "            detected_lang = result.get(\"language\", \"unknown\")\n",
    "\n",
    "            # others\n",
    "            if detected_lang != \"vi\":\n",
    "                print(f\"-> {detected_lang} detected: {input_path}\")\n",
    "                shutil.copy(input_path, os.path.join(other_dir, filename))\n",
    "                continue\n",
    "\n",
    "            # vi\n",
    "            result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, input_path, DEVICE)\n",
    "            words = [w for w in result_aligned[\"word_segments\"] if \"start\" in w and w[\"start\"] is not None]\n",
    "\n",
    "            audio = AudioSegment.from_file(input_path)\n",
    "            total_duration = len(audio) / 1000.0\n",
    "            \n",
    "            current_mark = 0.0\n",
    "            seg_index = 1\n",
    "\n",
    "            while current_mark < total_duration - target_duration * 0.8:\n",
    "                # start word >= current_mark\n",
    "                start_word_idx = None\n",
    "                for idx, w in enumerate(words):\n",
    "                    if w[\"start\"] >= current_mark:\n",
    "                        start_word_idx = idx\n",
    "                        break\n",
    "                \n",
    "                if start_word_idx is None:\n",
    "                    break\n",
    "\n",
    "                actual_start_time = words[start_word_idx][\"start\"]\n",
    "                if actual_start_time <= last_start_time:\n",
    "                    break\n",
    "                \n",
    "                current_segment_words = []\n",
    "                for j in range(start_word_idx, len(words)):\n",
    "                    current_segment_words.append(words[j])\n",
    "                    if words[j][\"end\"] - actual_start_time >= target_duration:\n",
    "                        break\n",
    "                \n",
    "                if not current_segment_words:\n",
    "                    break\n",
    "                    \n",
    "                seg_duration = current_segment_words[-1][\"end\"] - actual_start_time\n",
    "                if seg_duration < target_duration * 0.8:\n",
    "                    break\n",
    "\n",
    "                start_ms = int(actual_start_time * 1000)\n",
    "                end_ms = int(current_segment_words[-1][\"end\"] * 1000)\n",
    "                \n",
    "                segment_audio = audio[start_ms:end_ms]\n",
    "                text = \" \".join(w[\"word\"] for w in current_segment_words)\n",
    "                \n",
    "                out_filename = f\"{base_name}_seg_{seg_index:03d}.wav\"\n",
    "                segment_audio.export(os.path.join(output_dir, out_filename), format=\"wav\")\n",
    "\n",
    "                last_start_time = actual_start_time\n",
    "                current_mark += stride\n",
    "                seg_index += 1\n",
    "\n",
    "            print(f\"-> Done: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "    print(\"\\nAll done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc670e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"D:\\Study\\7-SP26\\DATxSLP\\Data_after_preprocessing\\test\"\n",
    "output_dir = r\"D:\\Study\\7-SP26\\DATxSLP\\Data_after_cut\\test_output\"\n",
    "other_lang_dir = r\"D:\\Study\\7-SP26\\DATxSLP\\Data_after_cut\\other_languages\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(other_lang_dir, exist_ok=True)\n",
    "\n",
    "TARGET_SECONDS = 5.0\n",
    "STRIDE_SECONDS = 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
