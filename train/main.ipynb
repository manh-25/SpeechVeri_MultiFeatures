{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f57328",
   "metadata": {},
   "source": [
    "# Speaker Verification Training & Inference\n",
    "\n",
    "Complete pipeline for speaker verification using:\n",
    "- **PTM Encoder**: WavLM/HuBERT/Wav2Vec2 (multi-layer weighted sum)\n",
    "- **Handcrafted Encoder**: MFBE + F0 features with CNN\n",
    "- **Fusion Methods**: Concatenation or Cross-Attention\n",
    "- **Backbone**: ECAPA-TDNN\n",
    "- **Loss**: AAM-Softmax\n",
    "- **Features**: Early stopping, LR scheduling, heatmap visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7dcb8c",
   "metadata": {},
   "source": [
    "## 1. Setup & Parse Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f712c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd97b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"experiment_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5828c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import (\n",
    "    BATCH_SIZE, NUM_EPOCHS, LEARNING_RATE, EMBEDDING_DIM,\n",
    "    MODE, FUSION_METHOD, FEATURE_MODE,\n",
    "    CHECKPOINT_DIR, BEST_MODEL_NAME,\n",
    ")\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse arguments for notebook - can be called from script or notebook\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Train Speaker Verification Model\")\n",
    "    \n",
    "    # --- DATA PATHS ---\n",
    "    parser.add_argument(\"--embedding_path\", type=str, \n",
    "                        default=\"C:/Users/dotru/STUDIE/FPTU/7_Spring2026/SLP301/SpeechVeri_MultiFeatures/embedding/raw_embeddings\")\n",
    "    parser.add_argument(\"--feature_path\", type=str,\n",
    "                        default=\"C:/Users/dotru/STUDIE/FPTU/7_Spring2026/SLP301/SpeechVeri_MultiFeatures/extract_feature_model/raw_extracted_features/MFBE + Pitch\")\n",
    "    \n",
    "    # --- MODE & ARCHITECTURE ---\n",
    "    parser.add_argument(\"--mode\", type=int, choices=[1, 2, 3], default=MODE)\n",
    "    parser.add_argument(\"--fusion_method\", type=str, choices=[\"concat\", \"cross_attention\", \"gating\"], default=FUSION_METHOD)\n",
    "    parser.add_argument(\"--feature_mode\", type=str, \n",
    "                        choices=[\"mfbe_pitch\", \"mfcc_pitch\", \"mfbe_only\", \"mfcc_only\", \"pitch_only\"],\n",
    "                        default=\"mfbe_pitch\")\n",
    "    \n",
    "    # --- HYPERPARAMETERS (Bổ sung để không cần vào config.py) ---\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--learning_rate\", \"--lr\", type=float, default=0.001)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100)\n",
    "    parser.add_argument(\"--optimizer\", type=str, choices=[\"adam\", \"sgd\"], default=\"adam\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=0.0001)\n",
    "    \n",
    "    # --- AAM-SOFTMAX SETTINGS (Rất quan trọng để điều chỉnh độ khó của bài toán) ---\n",
    "    parser.add_argument(\"--aam_margin\", type=float, default=0.2, help=\"Margin 'm' in AAM-Softmax\")\n",
    "    parser.add_argument(\"--aam_scale\", type=float, default=30, help=\"Scale 's' in AAM-Softmax\")\n",
    "    parser.add_argument(\"--embedding_dim\", type=int, default=512, help=\"Dimension of speaker embedding\")\n",
    "\n",
    "    # --- PERFORMANCE ---\n",
    "    parser.add_argument(\"--mixed_precision\", type=bool, default=True)\n",
    "    parser.add_argument(\"--early_stop_patience\", type=int, default=10)\n",
    "    parser.add_argument(\"--exp_name\", type=str, default=EXP_NAME)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    \n",
    "    # Parse with empty args for notebook mode\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    dim_map = {\n",
    "        \"mfbe_pitch\": 81, \"mfcc_pitch\": 41,\n",
    "        \"mfbe_only\": 80, \"mfcc_only\": 40, \"pitch_only\": 1\n",
    "    }\n",
    "    args.handcrafted_dim = dim_map.get(args.feature_mode, 81)\n",
    "    \n",
    "    return args\n",
    "\n",
    "# Parse arguments\n",
    "args = parse_args()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PARSED ARGUMENTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Embedding path: {args.embedding_path}\")\n",
    "print(f\"  Feature path: {args.feature_path}\")\n",
    "print(f\"  Mode: {args.mode} (1=PTM only, 2=Handcrafted only, 3=Fusion)\")\n",
    "print(f\"  Fusion method: {args.fusion_method if args.mode == 3 else 'N/A'}\")\n",
    "print(f\"  Feature mode: {args.feature_mode if args.mode in [2, 3] else 'N/A'}\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Learning rate: {args.learning_rate}\")\n",
    "print(f\"  Epochs: {args.epochs}\")\n",
    "print(f\"  Exp name: {args.exp_name or 'Auto-generated'}\")\n",
    "print(f\"  Seed: {args.seed}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db75816",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "\n",
    "# Generate experiment name if not provided\n",
    "if args.exp_name is None:\n",
    "    args.exp_name = f\"mode{args.mode}_fusion_{args.fusion_method}_feat_{args.feature_mode}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Experiment: {args.exp_name}\\n\")\n",
    "\n",
    "model, history, exp_dir = train(args)\n",
    "\n",
    "print(f\"\\n✓ Training completed!\")\n",
    "print(f\"  Results saved to: {exp_dir}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c45c4",
   "metadata": {},
   "source": [
    "## 3. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85176d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load history\n",
    "history_path = os.path.join(exp_dir, \"training_history.json\")\n",
    "\n",
    "with open(history_path, \"r\") as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history[\"train_loss\"], label=\"Train\", marker='o', markersize=3)\n",
    "axes[0].plot(history[\"val_loss\"], label=\"Val\", marker='s', markersize=3)\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training & Validation Loss\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history[\"train_accuracy\"], label=\"Train\", marker='o', markersize=3)\n",
    "axes[1].plot(history[\"val_accuracy\"], label=\"Val\", marker='s', markersize=3)\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Training & Validation Accuracy\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./outputs/training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best validation loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"Best validation accuracy: {max(history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b0168",
   "metadata": {},
   "source": [
    "## 4. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd58666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import load_checkpoint\n",
    "from model import AAMSoftmaxLoss\n",
    "\n",
    "# Load best model\n",
    "best_model_path = os.path.join(exp_dir, BEST_MODEL_NAME)\n",
    "model, _, _, _ = load_checkpoint(best_model_path, model)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"✓ Best model loaded from: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64953b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for testing (test_loader needs to be recreated)\n",
    "from dataset import create_data_loaders\n",
    "\n",
    "# Recreate test loader\n",
    "_, _, test_loader, _, num_speakers = create_data_loaders(\n",
    "    args.embedding_path, args.feature_path, args.mode, args.batch_size, num_workers=0\n",
    ")\n",
    "\n",
    "# Test on test set\n",
    "criterion = AAMSoftmaxLoss(num_speakers=num_speakers, embedding_dim=args.embedding_dim).to(device)\n",
    "from train import validate\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a3441",
   "metadata": {},
   "source": [
    "## 5. Gating Analysis (Only for Mode 3 + Gating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import analyze_gating_behavior\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Kiểm tra điều kiện để chạy phân tích\n",
    "if args.mode == 3 and args.fusion_method == \"gating\":\n",
    "    print(\"Đang thực hiện phân tích cơ chế Gating trên tập Test...\")\n",
    "    \n",
    "    # Gọi hàm phân tích từ train.py\n",
    "    # Lưu ý: Hàm này trả về 2 giá trị: gates (trọng số PTM) và labels\n",
    "    gates, labels = analyze_gating_behavior(model, test_loader, device, exp_dir)\n",
    "    \n",
    "    # Hiển thị biểu đồ phân phối trọng số đã được lưu\n",
    "    gate_plot_path = os.path.join(exp_dir, \"gating_analysis\", \"gate_distribution.png\")\n",
    "    if os.path.exists(gate_plot_path):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        img = mpimg.imread(gate_plot_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Phân phối trọng số Gating (Trục X > 0.5 ưu tiên PTM, < 0.5 ưu tiên Handcrafted)\")\n",
    "        plt.show()\n",
    "        \n",
    "    # In thông tin thống kê tóm tắt\n",
    "    ptm_wins = np.sum(gates > 0.5)\n",
    "    hc_wins = np.sum(gates <= 0.5)\n",
    "    print(f\"Thống kê nhanh:\")\n",
    "    print(f\"   - Số lần ưu tiên PTM (WavLM/HuBERT): {ptm_wins} ({100*ptm_wins/len(gates):.2f}%)\")\n",
    "    print(f\"   - Số lần ưu tiên Handcrafted (MFCC/Pitch): {hc_wins} ({100*hc_wins/len(gates):.2f}%)\")\n",
    "else:\n",
    "    print(\"ℹChế độ hiện tại không sử dụng Gating. Bỏ qua bước phân tích này.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d397c67",
   "metadata": {},
   "source": [
    "## 6. Experiment Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List all experiments\n",
    "exp_base_dir = \"./outputs/experiments\"\n",
    "if os.path.exists(exp_base_dir):\n",
    "    experiments = []\n",
    "    for exp_name_dir in sorted(os.listdir(exp_base_dir)):\n",
    "        exp_path = os.path.join(exp_base_dir, exp_name_dir)\n",
    "        results_file = os.path.join(exp_path, \"results.json\")\n",
    "        if os.path.exists(results_file):\n",
    "            with open(results_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                config = data.get(\"config\", {})\n",
    "                experiments.append({\n",
    "                    \"Experiment\": exp_name_dir,\n",
    "                    \"Mode\": config.get(\"mode\", \"\"),\n",
    "                    \"Fusion\": config.get(\"fusion_method\", \"N/A\"),\n",
    "                    \"Feature\": config.get(\"feature_mode\", \"N/A\"),\n",
    "                    \"Best Val Loss\": f\"{data.get('best_val_loss', 0):.4f}\",\n",
    "                    \"Epochs\": data.get(\"epochs_trained\", 0),\n",
    "                })\n",
    "    \n",
    "    if experiments:\n",
    "        df = pd.DataFrame(experiments)\n",
    "        print(\"\\n\" + \"=\"*120)\n",
    "        print(\"EXPERIMENT COMPARISON\")\n",
    "        print(\"=\"*120)\n",
    "        print(df.to_string(index=False))\n",
    "        print(\"=\"*120)\n",
    "    else:\n",
    "        print(\"No experiments found.\")\n",
    "else:\n",
    "    print(f\"Directory {exp_base_dir} does not exist yet.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
